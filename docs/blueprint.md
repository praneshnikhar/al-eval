# **App Name**: AI Model Evaluator

## Core Features:

- Dashboard: Dashboard for comparing model outputs across various prompts and metrics.
- Landing Page: Landing page with clear explanation of project, including documentation for prompt setup and contribution, model output, and metric usage.
- Prompt Loading: Loading of a common set of prompts to be tested on all models.
- Output Collection: Collect and store model outputs for each prompt.
- Automatic Evaluation: Automatic evaluation of outputs (e.g., toxicity detection). This feature relies on a toxicity-detection AI tool.
- Human Evaluation UI: UI for human evaluators to judge model outputs based on defined metrics (bias, reasoning, harm).
- Score Aggregation: Normalize and aggregate scores from automatic and human evaluations.

## Style Guidelines:

- Primary color: HSL(210, 70%, 50%) – A vibrant blue, represented as RGB hex #3399FF, evokes trust, intelligence, and clarity, fitting for a serious evaluation platform.
- Background color: HSL(210, 20%, 95%) – Very light blue/gray, RGB hex #F0F8FF, for a clean and unobtrusive backdrop, ensuring readability and focus on the content.
- Accent color: HSL(180, 60%, 40%) – A teal color, represented as RGB hex #339980, highlights interactive elements and important information.
- Body and headline font: 'Inter' sans-serif font for a clean and modern aesthetic.
- Use minimalist icons to represent metrics and functionalities.
- Dashboard layout should be clean and well-organized, using cards or tiles to display model comparison data.
- Subtle transitions and animations for loading states and data updates.